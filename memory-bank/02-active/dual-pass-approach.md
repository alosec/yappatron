# Dual-Pass ASR Processing

**Created:** 2026-01-09
**Updated:** 2026-01-09
**Status:** ‚úÖ IMPLEMENTED - Optional Toggle (Disabled by Default)

## Concept

Run ASR twice on the same audio for both speed and accuracy:

1. **First Pass (Real-time Streaming):** Parakeet EOU 120M
   - Fast, low-latency streaming (~80-160ms chunks)
   - Shows unpunctuated text immediately
   - Maintains real-time "ghost text" feel
   - ~5.73% WER (good but not perfect)

2. **Second Pass (Batch Re-processing):** Parakeet TDT 0.6b
   - Triggered on EOU detection
   - Processes saved audio chunk with larger, more accurate model
   - 600M parameters vs 120M (5x larger)
   - Potentially better accuracy
   - **Unknown:** Does it output punctuation?

## Architecture

```
Audio Input ‚Üí Buffer + Stream
                 ‚Üì              ‚Üì
            Save chunks    First Pass (Streaming)
                 ‚Üì         Parakeet EOU 120M
                 ‚Üì              ‚Üì
                 ‚Üì         Display unpunctuated
                 ‚Üì         (fast, ~5.73% WER)
                 ‚Üì              ‚Üì
            [EOU Detected] ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
          Second Pass (Batch)
          Parakeet TDT 0.6b
          Process saved audio
                 ‚Üì
          Better accuracy
          + Punctuation (?)
                 ‚Üì
          Replace text in-place
          (InputSimulator.applyTextUpdate)
```

## Comparison to Single-Pass Punctuation

### Single-Pass Approach (Punctuation Model Only)
```
Stream EOU 120M ‚Üí Unpunctuated text
                      ‚Üì
                  [On EOU]
                      ‚Üì
              Punctuation model
              (text ‚Üí text)
                      ‚Üì
              Add punctuation
              Same accuracy
```

### Dual-Pass Approach (Batch Re-processing)
```
Stream EOU 120M ‚Üí Unpunctuated text (~5.73% WER)
                      ‚Üì
                  [On EOU]
                      ‚Üì
              TDT 0.6b (batch)
              (audio ‚Üí text)
                      ‚Üì
              Better accuracy + punctuation (?)
```

## Trade-offs

| Aspect | Single-Pass (Punctuation) | Dual-Pass (Batch ASR) |
|--------|---------------------------|----------------------|
| **Accuracy improvement** | ‚ùå No (same ASR) | ‚úÖ Yes (larger model) |
| **Punctuation** | ‚úÖ Yes (dedicated model) | ‚ùì Unknown (TDT might not output) |
| **Latency** | ‚ö° Fast (~50-200ms) | üê¢ Slower (batch processing) |
| **Memory** | üíö Lower (one ASR model) | üü° Higher (audio buffering) |
| **Complexity** | üíö Simpler (one ASR) | üü° More complex (two ASR) |
| **Power usage** | üíö Lower (ASR once) | üü° Higher (ASR twice) |
| **Flexibility** | ‚úÖ Style variants (formal/casual) | ‚ùå Fixed output from model |

## ‚úÖ VERIFIED: TDT Outputs Punctuation!

**Finding:** Parakeet TDT 0.6b v3 **DOES output punctuation and capitalization**.

**Source:** [NVIDIA Parakeet TDT 0.6b v3 Model Card](https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3)

### Key Details from Documentation:

**Stated Features:**
> "Automatic **punctuation** and **capitalization**"

**Output Format:**
> **Output Type(s):** Text
> **Output Format:** String
> **Output Parameters:** 1D (text)
> **Other Properties Related to Output:** **Punctuations and Capitalizations included.**

**Training Data:**
> "All transcriptions preserve punctuation and capitalization."

**WER Calculation Note:**
> WERs are calculated after **removing Punctuation and Capitalization from reference and predicted text**.

### Implications:

‚úÖ **Dual-pass solves BOTH problems:**
- Improved accuracy (600M params vs 120M params)
- Punctuation and capitalization (native from model)

‚úÖ **No separate punctuation model needed**
- Simpler architecture
- Single post-processing step
- Lower latency (one model, not two)

‚úÖ **Implementation decision: CONFIRMED**
- Dual-pass is the clear winner
- One solution for both accuracy and formatting
- Worth the added complexity

## User Context: Previous Whisper Approach

> "Like how we previously were just using whisper which collects the whole audio chunk"

The Python prototype used Whisper in batch mode. Key differences:

**Previous (Whisper batch):**
- Wait for complete utterance
- Process entire audio chunk
- Display text once (with punctuation)
- No streaming, higher perceived latency

**Proposed (Dual-pass):**
- Stream first (fast, unpunctuated)
- Re-process on EOU (accurate, punctuated)
- User sees text immediately, then refinement
- Best of both worlds: speed + accuracy

## Implementation Considerations

### Audio Buffering
Need to save audio chunks during streaming:

```swift
class AudioChunkBuffer {
    private var currentUtteranceAudio: [AVAudioPCMBuffer] = []

    func append(_ buffer: AVAudioPCMBuffer) {
        // Save buffer for potential re-processing
        currentUtteranceAudio.append(copyBuffer(buffer))
    }

    func getCompleteUtterance() -> AVAudioPCMBuffer? {
        // Concatenate all buffers into single chunk
        return concatenate(currentUtteranceAudio)
    }

    func clear() {
        currentUtteranceAudio.removeAll()
    }
}
```

### Memory Management
- **Per utterance:** ~5-10 seconds of audio at 16kHz mono Float32
- **Memory usage:** ~5s √ó 16000 samples √ó 4 bytes = ~320KB per utterance
- **Acceptable:** Not significant overhead
- **Cleanup:** Clear buffer after processing to prevent accumulation

### Batch Processing Integration
FluidAudio supports batch processing with TDT models:

```swift
// Load batch TDT model (separate from streaming)
let batchManager = try await BatchAsrManager.load(.parakeetTdt0_6bV3)

// On EOU, re-process saved audio
let audioChunk = audioBuffer.getCompleteUtterance()
let refinedText = try await batchManager.transcribe(audioChunk)

// Replace streamed text with refined version
inputSimulator.applyTextUpdate(from: streamedText, to: refinedText)
audioBuffer.clear()
```

### Performance Concerns

**Latency:**
- TDT 0.6b: ~110√ó RTF on M4 Pro (1 min audio ‚âà 0.5s)
- 5-10s utterance: ~50-100ms batch processing time
- **Acceptable:** Within <200ms target if optimized

**Neural Engine Contention:**
- Streaming ASR already uses ANE
- Batch processing would compete for ANE resources
- **Mitigation:** Run batch on CPU if ANE busy, or queue sequentially

### Optional Setting
Make dual-pass optional:

```swift
enum TranscriptionMode {
    case fastOnly        // Streaming only (current behavior)
    case accurateRefine  // Streaming + batch refinement
}

// User preference
var transcriptionMode: TranscriptionMode = .fastOnly
```

**Use cases:**
- **Fast only:** Low-power mode, battery sensitive, casual use
- **Accurate refine:** Dictating important documents, formal writing

## Implementation Status

### ‚úÖ Phase 1: Research & Verification (COMPLETE)

1. **‚úÖ Verified TDT punctuation output** (critical!)
   - ‚úÖ Confirmed via NVIDIA model card documentation
   - ‚úÖ Model outputs punctuation and capitalization natively
   - ‚úÖ Decision: Dual-pass approach is optimal

### ‚úÖ Phase 2: Core Implementation (COMPLETE)

All core components implemented and building successfully:

   - ‚úÖ Created `AudioChunkBuffer` actor in [TranscriptionEngine.swift:58-102](../../packages/app/Yappatron/Sources/TranscriptionEngine.swift#L58-L102)
   - ‚úÖ Integrated with audio capture pipeline (saves buffers during streaming)
   - ‚úÖ Provides `getAsSamples()` to concatenate buffers into Float array

3. **‚úÖ Created batch processor**
   - ‚úÖ Implemented `BatchProcessor` actor in [BatchProcessor.swift](../../packages/app/Yappatron/Sources/BatchProcessor.swift)
   - ‚úÖ Loads Parakeet TDT 0.6b v3 models using FluidAudio's `AsrModels.downloadAndLoad(version: .v3)`
   - ‚úÖ Provides async `transcribe(_ samples: [Float])` method
   - ‚úÖ Logs latency and RTF for monitoring

4. **‚úÖ Created refinement coordinator**
   - ‚úÖ Implemented `TextRefinementManager` in [TextRefinementManager.swift](../../packages/app/Yappatron/Sources/TextRefinementManager.swift)
   - ‚úÖ Coordinates streaming ‚Üí batch workflow
   - ‚úÖ Uses existing `InputSimulator.applyTextUpdate()` for text replacement
   - ‚úÖ Detects whether changes are accuracy improvements or just formatting

5. **‚úÖ Integrated with app**
   - ‚úÖ Modified [YappatronApp.swift](../../packages/app/Yappatron/Sources/YappatronApp.swift) to initialize components
   - ‚úÖ Wired up `engine.onUtteranceComplete` callback to trigger refinement
   - ‚úÖ Added `handleRefinementComplete()` to finalize utterance after batch processing
   - ‚úÖ Batch processor initialization runs in parallel with streaming models

6. **‚úÖ Build successful**
   - ‚úÖ All compilation errors resolved
   - ‚úÖ Project builds cleanly with dual-pass system integrated

### ‚úÖ Phase 3: Testing & Validation (COMPLETE)

**Status:** Successfully tested with real-world dictation (2026-01-09 evening)

1. **‚úÖ Real usage testing**
   - ‚úÖ Both models load successfully (streaming + batch)
   - ‚úÖ Text replacement works smoothly
   - ‚úÖ No runtime errors encountered
   - ‚úÖ System handles natural speech patterns with pauses

2. **‚úÖ Quality evaluation**
   - ‚úÖ Punctuation quality: Excellent (periods, commas, capitalization)
   - ‚úÖ Accuracy: Improved from streaming model
   - ‚úÖ Multi-sentence utterances: Handled correctly
   - ‚úÖ EOU detection: 800ms debounce working well (doesn't cut off mid-thought)

3. **‚úÖ UX evaluation**
   - ‚úÖ Text replacement is NOT jarring - described as "really cool effect"
   - ‚úÖ Delete/retype animation works well
   - ‚úÖ Delays acceptable - EOU debounce takes "a little bit while" but necessary for natural pauses
   - ‚úÖ Overall UX: "Really close to exactly what we were hoping to enable"
   - ‚úÖ User verdict: "Really quite impressive"

### Key Observations from Testing

**What Works Well:**
- Immediate streaming text maintains real-time feel
- Smooth refinement with delete/retype effect
- Punctuation and capitalization are accurate
- Multiple sentences in single utterance handled correctly
- Natural pauses don't trigger premature EOU

**EOU Detection Tradeoff:**
- Current: 800ms silence debounce (reduced from 1280ms)
- User feedback: Slight perceptible delay but necessary and acceptable
- Handles natural "um", "uh" pauses without cutting off
- Keeps complete thoughts together as single utterances

**Potential Future Improvements:**
- Could make EOU debounce configurable (user preference)
- Consider full context refinement (currently only refines last utterance)
- Visual feedback for when refinement is processing

### ‚úÖ Phase 4: Optional Toggle Implementation (COMPLETE - 2026-01-09)

**Status:** Dual-pass refinement is now an optional feature controlled by menu bar toggle.

**Implementation:**
1. **‚úÖ Menu bar toggle:** "Dual-Pass Refinement (Punctuation)"
   - Located in menu bar right-click menu
   - Defaults to OFF (fast streaming-only mode)
   - Shows checkmark when enabled
   - Requires app restart to take effect (user is informed via alert)

2. **‚úÖ UserDefaults persistence:**
   - Setting stored in `enableDualPassRefinement` key
   - Persists across app restarts
   - Default value: `false` (disabled)

3. **‚úÖ Conditional initialization:**
   - Batch processor only initialized when toggle is ON
   - Refinement manager only created when toggle is ON
   - No performance/memory overhead when disabled
   - Graceful fallback if batch processor fails to initialize

4. **‚úÖ Dual behavior in handleFinalTranscription:**
   - **When disabled:** Immediate spacing/enter after EOU (current fast behavior)
   - **When enabled:** Wait for refinement, then add spacing/enter
   - Smooth transition between modes

**Benefits:**
- Users can choose speed vs accuracy/punctuation
- No breaking changes to existing workflow
- Opt-in for power users who want punctuation
- Fast default for coding/casual use
- Clean architecture with minimal conditional logic

**Commit:** 16ab51c - Reintroduce dual-pass refinement as optional menu toggle

### Remaining Tasks (Optional Enhancements)

1. **Performance benchmarking** (nice-to-have metrics)
   - [ ] Measure exact batch processing latency
   - [ ] Test with various utterance lengths (2s, 5s, 10s+)
   - [ ] Monitor memory usage over extended sessions
   - [ ] Profile Neural Engine utilization

2. **Future enhancements** (not critical)
   - [ ] Make EOU debounce configurable
   - [ ] Add visual feedback for refinement state
   - [ ] Consider full-context refinement (beyond single utterance)
   - [x] ~~Implement optional fast-only mode (toggle dual-pass)~~ ‚úÖ DONE

## Decision Criteria

**Choose Dual-Pass if:**
- ‚úÖ TDT outputs punctuation (solves both problems)
- ‚úÖ Latency is acceptable (<200ms perceived)
- ‚úÖ Accuracy improvement is significant (>2% WER reduction)
- ‚úÖ Memory overhead is manageable

**Stick with Single-Pass if:**
- ‚ùå TDT does NOT output punctuation (need separate model anyway)
- ‚ùå Latency is too high (>500ms)
- ‚ùå Accuracy improvement is marginal (<1% WER reduction)
- ‚ùå Complexity not justified by benefits

## Next Actions

**Immediate (before further architecture work):**
1. [ ] Research Parakeet TDT punctuation capabilities
2. [ ] Test batch TDT inference with sample audio
3. [ ] Document exact output format (capitalization, punctuation, etc.)

**If TDT outputs punctuation:**
1. [ ] Prototype dual-pass architecture
2. [ ] Benchmark latency and accuracy
3. [ ] Compare with single-pass punctuation approach
4. [ ] User testing for perceived quality

**If TDT does NOT output punctuation:**
1. [ ] Proceed with single-pass + separate punctuation model
2. [ ] Consider dual-pass only if accuracy improvement alone justifies complexity
3. [ ] Re-evaluate when FluidAudio adds streaming TDT support

## References

- [FluidInference/parakeet-tdt-0.6b-v3-coreml](https://huggingface.co/FluidInference/parakeet-tdt-0.6b-v3-coreml) - Batch model (multilingual)
- [FluidInference/parakeet-tdt-0.6b-v2-coreml](https://huggingface.co/FluidInference/parakeet-tdt-0.6b-v2-coreml) - Batch model (English)
- [NVIDIA Parakeet TDT v3](https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3) - Original model documentation
- [FluidAudio GitHub](https://github.com/FluidInference/FluidAudio) - API documentation for batch processing
