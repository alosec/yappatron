# Alternative: Dual-Pass ASR Processing

**Created:** 2026-01-09
**Status:** üî¨ Research - Needs Validation

## Concept

Run ASR twice on the same audio for both speed and accuracy:

1. **First Pass (Real-time Streaming):** Parakeet EOU 120M
   - Fast, low-latency streaming (~80-160ms chunks)
   - Shows unpunctuated text immediately
   - Maintains real-time "ghost text" feel
   - ~5.73% WER (good but not perfect)

2. **Second Pass (Batch Re-processing):** Parakeet TDT 0.6b
   - Triggered on EOU detection
   - Processes saved audio chunk with larger, more accurate model
   - 600M parameters vs 120M (5x larger)
   - Potentially better accuracy
   - **Unknown:** Does it output punctuation?

## Architecture

```
Audio Input ‚Üí Buffer + Stream
                 ‚Üì              ‚Üì
            Save chunks    First Pass (Streaming)
                 ‚Üì         Parakeet EOU 120M
                 ‚Üì              ‚Üì
                 ‚Üì         Display unpunctuated
                 ‚Üì         (fast, ~5.73% WER)
                 ‚Üì              ‚Üì
            [EOU Detected] ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
          Second Pass (Batch)
          Parakeet TDT 0.6b
          Process saved audio
                 ‚Üì
          Better accuracy
          + Punctuation (?)
                 ‚Üì
          Replace text in-place
          (InputSimulator.applyTextUpdate)
```

## Comparison to Single-Pass Punctuation

### Single-Pass Approach (Punctuation Model Only)
```
Stream EOU 120M ‚Üí Unpunctuated text
                      ‚Üì
                  [On EOU]
                      ‚Üì
              Punctuation model
              (text ‚Üí text)
                      ‚Üì
              Add punctuation
              Same accuracy
```

### Dual-Pass Approach (Batch Re-processing)
```
Stream EOU 120M ‚Üí Unpunctuated text (~5.73% WER)
                      ‚Üì
                  [On EOU]
                      ‚Üì
              TDT 0.6b (batch)
              (audio ‚Üí text)
                      ‚Üì
              Better accuracy + punctuation (?)
```

## Trade-offs

| Aspect | Single-Pass (Punctuation) | Dual-Pass (Batch ASR) |
|--------|---------------------------|----------------------|
| **Accuracy improvement** | ‚ùå No (same ASR) | ‚úÖ Yes (larger model) |
| **Punctuation** | ‚úÖ Yes (dedicated model) | ‚ùì Unknown (TDT might not output) |
| **Latency** | ‚ö° Fast (~50-200ms) | üê¢ Slower (batch processing) |
| **Memory** | üíö Lower (one ASR model) | üü° Higher (audio buffering) |
| **Complexity** | üíö Simpler (one ASR) | üü° More complex (two ASR) |
| **Power usage** | üíö Lower (ASR once) | üü° Higher (ASR twice) |
| **Flexibility** | ‚úÖ Style variants (formal/casual) | ‚ùå Fixed output from model |

## ‚úÖ VERIFIED: TDT Outputs Punctuation!

**Finding:** Parakeet TDT 0.6b v3 **DOES output punctuation and capitalization**.

**Source:** [NVIDIA Parakeet TDT 0.6b v3 Model Card](https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3)

### Key Details from Documentation:

**Stated Features:**
> "Automatic **punctuation** and **capitalization**"

**Output Format:**
> **Output Type(s):** Text
> **Output Format:** String
> **Output Parameters:** 1D (text)
> **Other Properties Related to Output:** **Punctuations and Capitalizations included.**

**Training Data:**
> "All transcriptions preserve punctuation and capitalization."

**WER Calculation Note:**
> WERs are calculated after **removing Punctuation and Capitalization from reference and predicted text**.

### Implications:

‚úÖ **Dual-pass solves BOTH problems:**
- Improved accuracy (600M params vs 120M params)
- Punctuation and capitalization (native from model)

‚úÖ **No separate punctuation model needed**
- Simpler architecture
- Single post-processing step
- Lower latency (one model, not two)

‚úÖ **Implementation decision: CONFIRMED**
- Dual-pass is the clear winner
- One solution for both accuracy and formatting
- Worth the added complexity

## User Context: Previous Whisper Approach

> "Like how we previously were just using whisper which collects the whole audio chunk"

The Python prototype used Whisper in batch mode. Key differences:

**Previous (Whisper batch):**
- Wait for complete utterance
- Process entire audio chunk
- Display text once (with punctuation)
- No streaming, higher perceived latency

**Proposed (Dual-pass):**
- Stream first (fast, unpunctuated)
- Re-process on EOU (accurate, punctuated)
- User sees text immediately, then refinement
- Best of both worlds: speed + accuracy

## Implementation Considerations

### Audio Buffering
Need to save audio chunks during streaming:

```swift
class AudioChunkBuffer {
    private var currentUtteranceAudio: [AVAudioPCMBuffer] = []

    func append(_ buffer: AVAudioPCMBuffer) {
        // Save buffer for potential re-processing
        currentUtteranceAudio.append(copyBuffer(buffer))
    }

    func getCompleteUtterance() -> AVAudioPCMBuffer? {
        // Concatenate all buffers into single chunk
        return concatenate(currentUtteranceAudio)
    }

    func clear() {
        currentUtteranceAudio.removeAll()
    }
}
```

### Memory Management
- **Per utterance:** ~5-10 seconds of audio at 16kHz mono Float32
- **Memory usage:** ~5s √ó 16000 samples √ó 4 bytes = ~320KB per utterance
- **Acceptable:** Not significant overhead
- **Cleanup:** Clear buffer after processing to prevent accumulation

### Batch Processing Integration
FluidAudio supports batch processing with TDT models:

```swift
// Load batch TDT model (separate from streaming)
let batchManager = try await BatchAsrManager.load(.parakeetTdt0_6bV3)

// On EOU, re-process saved audio
let audioChunk = audioBuffer.getCompleteUtterance()
let refinedText = try await batchManager.transcribe(audioChunk)

// Replace streamed text with refined version
inputSimulator.applyTextUpdate(from: streamedText, to: refinedText)
audioBuffer.clear()
```

### Performance Concerns

**Latency:**
- TDT 0.6b: ~110√ó RTF on M4 Pro (1 min audio ‚âà 0.5s)
- 5-10s utterance: ~50-100ms batch processing time
- **Acceptable:** Within <200ms target if optimized

**Neural Engine Contention:**
- Streaming ASR already uses ANE
- Batch processing would compete for ANE resources
- **Mitigation:** Run batch on CPU if ANE busy, or queue sequentially

### Optional Setting
Make dual-pass optional:

```swift
enum TranscriptionMode {
    case fastOnly        // Streaming only (current behavior)
    case accurateRefine  // Streaming + batch refinement
}

// User preference
var transcriptionMode: TranscriptionMode = .fastOnly
```

**Use cases:**
- **Fast only:** Low-power mode, battery sensitive, casual use
- **Accurate refine:** Dictating important documents, formal writing

## Implementation Status

### ‚úÖ Phase 1: Research & Verification (COMPLETE)

1. **‚úÖ Verified TDT punctuation output** (critical!)
   - ‚úÖ Confirmed via NVIDIA model card documentation
   - ‚úÖ Model outputs punctuation and capitalization natively
   - ‚úÖ Decision: Dual-pass approach is optimal

### ‚úÖ Phase 2: Core Implementation (COMPLETE)

All core components implemented and building successfully:

   - ‚úÖ Created `AudioChunkBuffer` actor in [TranscriptionEngine.swift:58-102](../../packages/app/Yappatron/Sources/TranscriptionEngine.swift#L58-L102)
   - ‚úÖ Integrated with audio capture pipeline (saves buffers during streaming)
   - ‚úÖ Provides `getAsSamples()` to concatenate buffers into Float array

3. **‚úÖ Created batch processor**
   - ‚úÖ Implemented `BatchProcessor` actor in [BatchProcessor.swift](../../packages/app/Yappatron/Sources/BatchProcessor.swift)
   - ‚úÖ Loads Parakeet TDT 0.6b v3 models using FluidAudio's `AsrModels.downloadAndLoad(version: .v3)`
   - ‚úÖ Provides async `transcribe(_ samples: [Float])` method
   - ‚úÖ Logs latency and RTF for monitoring

4. **‚úÖ Created refinement coordinator**
   - ‚úÖ Implemented `TextRefinementManager` in [TextRefinementManager.swift](../../packages/app/Yappatron/Sources/TextRefinementManager.swift)
   - ‚úÖ Coordinates streaming ‚Üí batch workflow
   - ‚úÖ Uses existing `InputSimulator.applyTextUpdate()` for text replacement
   - ‚úÖ Detects whether changes are accuracy improvements or just formatting

5. **‚úÖ Integrated with app**
   - ‚úÖ Modified [YappatronApp.swift](../../packages/app/Yappatron/Sources/YappatronApp.swift) to initialize components
   - ‚úÖ Wired up `engine.onUtteranceComplete` callback to trigger refinement
   - ‚úÖ Added `handleRefinementComplete()` to finalize utterance after batch processing
   - ‚úÖ Batch processor initialization runs in parallel with streaming models

6. **‚úÖ Build successful**
   - ‚úÖ All compilation errors resolved
   - ‚úÖ Project builds cleanly with dual-pass system integrated

### Remaining Tasks

1. **Test with real usage**
   - [ ] Run app and test actual transcription
   - [ ] Verify both models load successfully
   - [ ] Confirm text replacement works smoothly
   - [ ] Check for any runtime errors

2. **Benchmark & evaluate**
   - [ ] Measure batch processing latency (target <200ms)
   - [ ] Compare accuracy (streaming vs batch)
   - [ ] Test with various utterance lengths (2s, 5s, 10s+)
   - [ ] Verify punctuation quality
   - [ ] Check memory usage (both models loaded)
   - [ ] Monitor Neural Engine contention

3. **UX refinement**
   - [ ] Determine if text replacement is jarring
   - [ ] Consider visual feedback for refinement
   - [ ] Test with different text input contexts
   - [ ] Evaluate if delays are acceptable

## Decision Criteria

**Choose Dual-Pass if:**
- ‚úÖ TDT outputs punctuation (solves both problems)
- ‚úÖ Latency is acceptable (<200ms perceived)
- ‚úÖ Accuracy improvement is significant (>2% WER reduction)
- ‚úÖ Memory overhead is manageable

**Stick with Single-Pass if:**
- ‚ùå TDT does NOT output punctuation (need separate model anyway)
- ‚ùå Latency is too high (>500ms)
- ‚ùå Accuracy improvement is marginal (<1% WER reduction)
- ‚ùå Complexity not justified by benefits

## Next Actions

**Immediate (before further architecture work):**
1. [ ] Research Parakeet TDT punctuation capabilities
2. [ ] Test batch TDT inference with sample audio
3. [ ] Document exact output format (capitalization, punctuation, etc.)

**If TDT outputs punctuation:**
1. [ ] Prototype dual-pass architecture
2. [ ] Benchmark latency and accuracy
3. [ ] Compare with single-pass punctuation approach
4. [ ] User testing for perceived quality

**If TDT does NOT output punctuation:**
1. [ ] Proceed with single-pass + separate punctuation model
2. [ ] Consider dual-pass only if accuracy improvement alone justifies complexity
3. [ ] Re-evaluate when FluidAudio adds streaming TDT support

## References

- [FluidInference/parakeet-tdt-0.6b-v3-coreml](https://huggingface.co/FluidInference/parakeet-tdt-0.6b-v3-coreml) - Batch model (multilingual)
- [FluidInference/parakeet-tdt-0.6b-v2-coreml](https://huggingface.co/FluidInference/parakeet-tdt-0.6b-v2-coreml) - Batch model (English)
- [NVIDIA Parakeet TDT v3](https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3) - Original model documentation
- [FluidAudio GitHub](https://github.com/FluidInference/FluidAudio) - API documentation for batch processing
