---
import Layout from '../layouts/Layout.astro';
---

<Layout title="Yappatron">
  <main>
    <div class="hero">
      <h1><span>ðŸŒ¸</span> Yappatron</h1>
      <p class="tagline">Just yap.</p>
      <p>Always-on voice dictation for macOS.<br/>No hotkeys. No toggles. Just talk.</p>
      <div class="buttons">
        <a href="https://github.com/alosec/yappatron" class="btn btn-primary">View on GitHub</a>
        <a href="#install" class="btn btn-secondary">Get Started</a>
      </div>
    </div>

    <hr />

    <h2>Features</h2>
    
    <div class="features">
      <div class="feature">
        <h3>ðŸ”Š Always Listening</h3>
        <p>No push-to-talk. Start talking, words appear. Stop talking, it waits.</p>
      </div>
      <div class="feature">
        <h3>âš¡ 160ms Latency</h3>
        <p>Real-time streaming. Characters appear as you speak.</p>
      </div>
      <div class="feature">
        <h3>ðŸ”’ Fully Local</h3>
        <p>All processing on-device. No cloud. No data leaves your machine.</p>
      </div>
      <div class="feature">
        <h3>ðŸ§  Neural Engine</h3>
        <p>Runs on Apple Silicon ANE. Efficient, not draining your battery.</p>
      </div>
    </div>

    <hr />

    <h2>How It Works</h2>
    
    <div class="terminal">
      <p><span class="prompt">~</span> yappatron</p>
      <p>Loading parakeet-eou-120m...</p>
      <p>Listening...</p>
      <p></p>
      <p>[speaking] <span class="output">Hello world this is me talking naturally</span></p>
      <p>[done â†µ]</p>
    </div>

    <ol>
      <li><strong>Mic capture</strong> â€” AVFoundation grabs audio, resamples to 16kHz</li>
      <li><strong>Streaming ASR</strong> â€” 160ms chunks fed to Parakeet model on Neural Engine</li>
      <li><strong>Ghost text</strong> â€” Partials stream into focused input with live corrections</li>
      <li><strong>End of utterance</strong> â€” Model detects you're done, optionally presses Enter</li>
    </ol>

    <hr />

    <h2 id="install">Install</h2>

    <pre><code>git clone https://github.com/alosec/yappatron
cd yappatron/packages/app/Yappatron
swift build</code></pre>

    <h3>Requirements</h3>
    <ul>
      <li>macOS 14+ (Sonoma)</li>
      <li>Apple Silicon</li>
      <li>Microphone permission</li>
      <li>Accessibility permission (keystroke injection)</li>
    </ul>

    <hr />

    <h2>Status</h2>
    <p>
      <strong>Alpha.</strong> Core streaming works great. Still ironing out bugs.
      See <a href="https://github.com/alosec/yappatron/tree/main/memory-bank/02-active">active work</a>.
    </p>

    <hr />

    <h2>Philosophy</h2>
    <blockquote>
      <p>The best interface is no interface.</p>
    </blockquote>
    <p>
      Voice dictation should be invisible. Think, speak, words appear.
      No buttons, no modes, no cognitive load.
    </p>

    <footer>
      <p>Made with ðŸŒ¸ for yappers</p>
      <p><a href="https://github.com/alosec/yappatron">GitHub</a></p>
    </footer>
  </main>
</Layout>
